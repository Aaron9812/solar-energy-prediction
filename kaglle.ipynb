{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n\nThe purpose of this notebook is to analyze the data and then modelize the concrete strength based on the features given in the dataset.\n\nTo reach this goal, we will follow the following steps:\n- produce an exploratory analysis of the data, the role of which is to assess the quality of the data and especially to identify highly correlated features\n- build a model based on stacking\n- optimize this model in terms of the number of basic models and the number of features.\n\nFor this experience, we will keep:\n- 6 models having a train score greater than 0.8\n- 4 features having a correlation coefficient smaller than 0.75.\n\nThe results are stored in a [database in Kaggle](https://www.kaggle.com/datasets/philippebillet/stacking-importance), and they are analyzed in [this notebook](https://www.kaggle.com/code/philippebillet/stacking-importances-result-analysis).\n\nThis notebook has been generated using [EZStacking](https://github.com/phbillet/EZStacking).\n\n_N.B._: \n- as it seems that it is not possible to edit a Kaggle dataset from a Kaggle notebook, this data have been generated directly on my PC\n- for more details on how it works, just follow the links given above.","metadata":{}},{"cell_type":"markdown","source":"# EDA & Modelling","metadata":{}},{"cell_type":"code","source":"random_state = 42","metadata":{"execution":{"iopub.status.busy":"2023-01-26T10:01:18.294844Z","iopub.execute_input":"2023-01-26T10:01:18.295833Z","iopub.status.idle":"2023-01-26T10:01:18.328723Z","shell.execute_reply.started":"2023-01-26T10:01:18.295705Z","shell.execute_reply":"2023-01-26T10:01:18.327506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Package loading","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os\nimport gc\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')\nimport re\nimport math\nfrom sklearn.base import BaseEstimator\nfrom sklearn.base import TransformerMixin\nfrom sklearn.neighbors import LocalOutlierFactor\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.gaussian_process.kernels import WhiteKernel\nfrom sklearn.gaussian_process.kernels import ConstantKernel\nfrom sklearn.gaussian_process.kernels import Matern\nfrom sklearn.gaussian_process.kernels import RationalQuadratic\nfrom sklearn.gaussian_process.kernels import ExpSineSquared\nfrom sklearn.gaussian_process.kernels import DotProduct\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\nfrom sklearn import set_config\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import FunctionTransformer\nfrom sklearn.gaussian_process import GaussianProcessRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import AdaBoostRegressor\nfrom sklearn.ensemble import HistGradientBoostingRegressor\nfrom sklearn.ensemble import StackingRegressor\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom pandas.api.types import is_numeric_dtype\nfrom itertools import product\nfrom joblib import dump\nfrom scipy import stats\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.compose import make_column_selector\nfrom sklearn.compose import make_column_transformer\nfrom yellowbrick.model_selection import learning_curve\nfrom yellowbrick.model_selection import feature_importances\nfrom yellowbrick.features import rank1d\nfrom yellowbrick.features import rank2d\nfrom yellowbrick.contrib.missing import MissingValuesBar\nfrom yellowbrick.contrib.missing import MissingValuesDispersion\nfrom yellowbrick.target.feature_correlation import feature_correlation\nfrom yellowbrick.regressor import prediction_error\nfrom yellowbrick.regressor import residuals_plot\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport sys\nfrom scipy import stats\nfrom pandas.api.types import is_numeric_dtype\nfrom sklearn.base import BaseEstimator, is_classifier, is_regressor, TransformerMixin\nfrom sklearn.model_selection import train_test_split, RepeatedStratifiedKFold\nfrom sklearn.metrics import ConfusionMatrixDisplay, classification_report\nfrom sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\nfrom sklearn.inspection import partial_dependence\nfrom sklearn.inspection import PartialDependenceDisplay\nfrom sklearn.inspection import permutation_importance\nfrom sklearn.metrics import mean_squared_error, r2_score, accuracy_score, f1_score, recall_score \n# Technical functions\n\ndef plot_dataframe_structure(df):\n    \"\"\"\n    Plot dataframe structure: It shows the different data types in the dataframe.\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    \n    Returns\n    -------\n    Plotting\n    \"\"\"\n    plt.figure()\n    df.dtypes.value_counts().plot.pie(ylabel='')\n    plt.title('Data types')\n    plt.show()\n\ndef plot_categorical(df):\n    \"\"\"\n    Plot the number of different values for each categorical feature in the dataframe.\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    \n    Returns\n    -------\n    Plotting\n    \"\"\"\n    plt.figure()\n    df.nunique().plot.bar()\n    plt.title('Number of different values')\n    plt.show()\n    \ndef duplicates(df):\n    \"\"\"\n    Remove the duplicate rows from dataframe.\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    \n    Returns\n    -------\n    df: Pandas dataframe without duplicate rows \n    \"\"\"    \n    duplicate_rows_df = df[df.duplicated()]\n    if duplicate_rows_df.shape[0] > 0:\n       print('Number of rows before removing:', df.count()[0])\n       print('Number of duplicate rows:', duplicate_rows_df.shape[0])\n       df = df.drop_duplicates()\n       print('Number of rows after removing:', df.count()[0])\n    else:\n       print('No duplicate rows.')\n    return df\n\ndef drop_na(df, threshold_NaN):\n    \"\"\"\n    Remove the columns from dataframe containing NaN depending on threshold_NaN.\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    threshold_NaN: in [0, 1], from GUI\n    \n    Returns\n    -------\n    df: Pandas dataframe \n    drop_cols: list of dropped columns\n    \"\"\"    \n    isna_stat = (df.isna().sum()/df.shape[0]).sort_values(ascending=True)\n    drop_cols = []\n    if isna_stat.max() > 0.0:\n       drop_cols = np.array(isna_stat[isna_stat > threshold_NaN].index)\n       print('Drop columns containing more than', threshold_NaN*100,'% of NaN:', drop_cols)\n       df = df.drop(drop_cols, axis=1)\n    else:\n       print('No need to drop columns.')\n    return df, drop_cols\n\ndef encoding(df, threshold_cat, target_col):\n    \"\"\"\n    Encode the data.\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    threshold_cat: integer, if the number of different values of a given column is less than this limit, \n    this column is considered as categorical. \n    \n    Returns\n    -------\n    df: Pandas dataframe \n    encoded_cols: Pandas dataframe of columns with their encoding and range\n    \"\"\"      \n    encoded_cols = []\n    for c in df.columns:\n        if df[c].dtypes == 'object' or df[c].dtypes.name == 'category': \n           encoded_cols.append([c, 'cat', df[c].dropna().unique().tolist()])\n           print('Encoding object column:', c)\n           df[c] = df[c].factorize()[0].astype(np.int)\n        elif is_numeric_dtype(df[c]): \n             if df[c].unique().shape[0] > threshold_cat: \n                encoded_cols.append([c, 'num', [df[c].min(), df[c].max()]])\n                print('Encoding numeric column:', c)\n                df[c]=(df[c]-df[c].mean())/df[c].std()\n             else:\n                print('Column ', c,' is categorical.')\n                encoded_cols.append([c, 'cat', df[c].dropna().unique().tolist()])\n        else: \n             print('Unknown type ', df[c].dtypes,' for column:',c) \n             df = df.drop(c, axis=1)\n             drop_cols = np.unique(np.concatenate((drop_cols, c)))\n    encoded_cols = pd.DataFrame(np.array(encoded_cols), columns=['column_name', 'column_type', 'column_range'])\n    encoded_cols = encoded_cols.loc[encoded_cols['column_name'] != target_col]\n    encoded_cols.to_csv('schema.csv', index=False)\n    return df, encoded_cols\n\ndef imputation(df):\n    \"\"\"\n    Impute NaN in the dataframe using IterativeImputer.\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    \n    Returns\n    -------\n    df: Pandas dataframe \n    \"\"\"        \n    isna_stat = (df.isna().sum()/df.shape[0]).sort_values(ascending=True) \n    if isna_stat.max() > 0.0: \n       print('Imputing NaN using IterativeImputer') \n       df = pd.DataFrame(IterativeImputer(random_state=0).fit_transform(df), columns = df.columns)  \n    else: \n       print('No need to impute data.')\n    return df\n\ndef outliers(df, threshold_Z):\n    \"\"\"\n    Remove the outliers from dataframe according to Z_score.\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    threshold_Z: number from GUI. \n    \n    Returns\n    -------\n    df: Pandas dataframe. \n    \"\"\"  \n    Z_score = np.abs(stats.zscore(df)) \n    df_o_Z = df[(Z_score < threshold_Z).all(axis=1)]\n    if df_o_Z.shape[0] != 0:\n       print('Using Z_score, ', str(df.shape[0] - df_o_Z.shape[0]) ,' rows will be suppressed.') \n       df = df_o_Z\n    else:\n       print('Possible problem with outliers treatment, check threshold_Z') \n    return df\n\ndef correlated_columns(df, threshold_corr, target_col):\n    \"\"\"\n    Display correlation matrix of features, and returns the list of the too correlated features\n    according to threshold_corr.\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    threshold_corr: number from GUI\n    target: target column\n    Returns\n    -------\n    correlated_features: list of the features having a correlation greater than threshold_corr. \n    \"\"\"  \n    df = df.drop(target_col, axis=1)\n    corr_matrix = df.corr() \n    correlated_features=[]\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold_corr: # we are interested in absolute coeff value\n               colname = corr_matrix.columns[i]  # getting the name of column\n               correlated_features.append(colname)\n    correlated_features = list(dict.fromkeys(correlated_features))\n    return correlated_features\n\ndef plot_sns_corr_class(df, target_col):\n    \"\"\"\n    Plot correlation information for classification problem (if Seaborn option is checked).\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    target_col: name of the target column. \n    \n    Returns\n    -------\n    Plotting. \n    \"\"\"     \n    g = sns.PairGrid(df, hue=target_col) \n    g.map_upper(sns.scatterplot) \n    g.map_lower(sns.kdeplot) \n    g.map_diag(sns.kdeplot, lw=3, legend=False) \n    g.add_legend() \n    g.fig.suptitle('Pairwise data relationships', y=1.01) \n    plt.show()\n    \ndef plot_sns_corr_regre(df, target_col):\n    \"\"\"\n    Plot correlation information for regression problem (if Seaborn option is checked).\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    target_col: name of the target column. \n    \n    Returns\n    -------\n    Plotting. \n    \"\"\"      \n    g = sns.PairGrid(df)\n    g.map_upper(sns.scatterplot)\n    g.map_lower(sns.kdeplot)\n    g.map_diag(sns.kdeplot, lw=3, legend=False)\n    g.fig.suptitle('Pairwise data relationships', y=1.01)\n    plt.show()\n    \nclass Decorrelator(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Decorrelator is a class used to eliminate too correlated columns depending on a threshold during preprocessing.\n\n    Parameters\n    ----------\n    threshold_corr\n    \"\"\"  \n    def __init__(self, threshold):\n        self.threshold = threshold\n        self.correlated_columns = None\n\n    def fit(self, X, y=None):\n        correlated_features = set()  \n        if not isinstance(X, pd.DataFrame):\n           X = pd.DataFrame(X)\n        corr_matrix = X.corr()\n        for i in range(len(corr_matrix.columns)):\n            for j in range(i):\n                if abs(corr_matrix.iloc[i, j]) > self.threshold: # we are interested in absolute coeff value\n                    colname = corr_matrix.columns[i]  # getting the name of column\n                    correlated_features.add(colname)\n        self.correlated_features = correlated_features\n        return self\n\n    def transform(self, X, y=None, **kwargs):\n        return (pd.DataFrame(X)).drop(labels=self.correlated_features, axis=1)\n    \nclass ColumnsDropper(BaseEstimator, TransformerMixin):\n    \"\"\"\n    ColumnsDropper is a class used to drop columns from a dataset.\n\n    Parameters\n    ----------\n    cols : list of columns dropped by the transformer\n    \"\"\"  \n    def __init__(self, cols):\n        if not isinstance(cols, list):\n            self.cols = [cols]\n        else:\n            self.cols = cols\n\n    def fit(self, X: pd.DataFrame, y: pd.Series):\n        # there is nothing to fit\n        return self\n\n    def transform(self, X:pd.DataFrame):\n        X = X.copy()\n        return X[self.cols]    \n    \ndef model_filtering(level_0, model_imp, nb_model, score_stack, threshold_score):\n    \"\"\"\n    Suppress estimators from level 0 having a test score smaller than threshold_score (from score_stack), then \n    keep nb_model best estimators (according to model_imp).\n    Parameters\n    ----------\n    level_0: list of estimators of level 0\n    model_imp: sorted array of model importance\n    nb_model : number of model to keep\n    score_stack: accuracy of estimators on train and test sets in a tabular\n    threshold_score : minimal score\n    \n    Returns\n    -------\n    list of filtered estimators of level 0\n    \"\"\"\n    # it is not possible to keep more models than we initially have\n    if nb_model > len(level_0):\n       nb_model = len(level_0)\n    \n    # keep model names and test scores\n    score_stack = np.delete(np.delete(score_stack, 1, axis =1), -1, axis = 0)\n    # keep models having test score greater than threshold_score \n    score_stack = score_stack[score_stack[:,1] > threshold_score]\n    \n    # it is not possible to keep more models than we have filtered    \n    if nb_model > len(score_stack):\n       nb_model = len(score_stack)\n    \n    # keep models (in importance array) having test score greater than threshold_score\n    model_imp = model_imp[np.in1d(model_imp[:, 0], score_stack)]\n    model_imp_f = model_imp[np.argpartition(model_imp[:,1], -nb_model)[-nb_model:]].T[0]\n    \n    return list(filter(lambda x: x[0] in model_imp_f, level_0))\n\ndef feature_filtering(feature_importance, nb_feature):\n    \"\"\"\n    Separate features in two lists, the first one contains the nb_feature most important features, \n    the second one contains the complement\n    Parameters\n    ----------\n    feature_importance: array of features with their importance\n    nb_feature: number of features we want to keep\n    \n    Returns\n    -------\n    best_feature: list of nb_feature most important features\n    worst_feature: list of the worst important features\n    \"\"\"\n    # check nb_feature\n    if nb_feature > feature_importance.shape[0]:\n       nb_feature = feature_importance.shape[0] \n    \n    best_feature = feature_importance[np.argpartition(feature_importance[:,1], -nb_feature)[-nb_feature:]].T[0]\n    worst_feature = list(set(feature_importance.T[0]) - set(best_feature))\n\n    return best_feature, worst_feature\n\ndef split(X, y, random_state, test_size=0.33, threshold_entropy=0.7, undersampling=False, undersampler=None):\n    \"\"\"\n    Split dataframe into train and test sets.\n    If the Shannon entropy of the target dataset is less than 0.7, RepeatedStratifiedKFold is used\n\n    Parameters\n    ----------\n    X: feature dataframe\n    y: target dataframe\n    \n    Returns\n    -------\n    X_train: train feature dataframe \n    X_test: test feature dataframe\n    y_train: train target dataframe\n    y_test: test target dataframe\n    \"\"\"\n    s_e = shannon_entropy(y)\n    if s_e < threshold_entropy:\n       if undersampling: \n          if undersampler == 'Random': \n             from imblearn.under_sampling import RandomUnderSampler\n             us = RandomUnderSampler()\n          elif undersampler == 'Centroids': \n             from imblearn.under_sampling import ClusterCentroids\n             us = ClusterCentroids()\n          elif undersampler == 'AllKNN': \n             from imblearn.under_sampling import AllKNN\n             us = AllKNN()\n          elif undersampler == 'TomekLinks': \n             from imblearn.under_sampling import TomekLinks\n             us = TomekLinks()\n          else:\n             print(\"Unknown undersampler\")       \n          X, y = us.fit_resample(X, y)\n          print(\"Shannon Entropy = {:.4}, split using undersampler {} and RepeatedStratifiedKFold\".format(s_e, undersampler)) \n       else: \n          print(\"Shannon Entropy = {:.4}, split using RepeatedStratifiedKFold\".format(s_e)) \n       skfold = RepeatedStratifiedKFold(n_splits=5, random_state = random_state)\n       # enumerate the splits and summarize the distributions\n       for ind_train, ind_test in skfold.split(X, y):\n           X_train, X_test = X.iloc[ind_train], X.iloc[ind_test]\n           y_train, y_test = y.iloc[ind_train], y.iloc[ind_test] \n    else:    \n       X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, stratify=None,\\\n                                                           shuffle=True, random_state = random_state)\n    return X_train, X_test, y_train, y_test\n    \ndef downcast_dtypes(df):\n    \"\"\"\n    Compress dataframe\n\n    Parameters\n    ----------\n    df: Pandas dataframe\n    \n    Returns\n    -------\n    df: Pandas dataframe\n    \"\"\"      \n    start_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage of dataframe is {:.2f}' \n                     'MB').format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n    end_mem = df.memory_usage().sum() / 1024**2\n    print(('Memory usage after optimization is: {:.2f}' \n                              'MB').format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) / start_mem))\n    return df\n\ndef shannon_entropy(y):\n    \"\"\"\n    Compute Shannon entropy of a dataset\n\n    Parameters\n    ----------\n    y: univariate Pandas dataframe\n    \n    Returns\n    -------\n    shannon entropy: float\n    \"\"\"     \n    from collections import Counter\n    from numpy import log\n    \n    n = len(y)\n    classes = [(clas,float(count)) for clas,count in Counter(y).items()]\n    k = len(classes)\n    \n    H = -sum([ (count/n) * log((count/n)) for clas,count in classes]) #shannon entropy\n    return H/log(k)\n\ndef score_stacking_c(model, X_train, y_train, X_test, y_test):\n    \"\"\"\n    Compute the score of the stacked classification estimator and of each level_0 estimator\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X_train: train feature dataframe \n    X_test: test feature dataframe\n    y_train: train target dataframe\n    y_test: test target dataframe\n    \n    Returns\n    -------\n    plotting: accuracy of estimators on train and test sets\n    res_stack: accuracy of estimators on train and test sets in a tabular\n    \"\"\"       \n    nb_estimators = len(model.estimators_)\n    res_stack = np.empty((nb_estimators + 1, 3), dtype='object')\n    m_t_x_train = model.transform(X_train)\n    for j in range(nb_estimators):\n        res_stack [j, 0] = [*model.named_estimators_.keys()][j]\n        if m_t_x_train.shape[1] == nb_estimators: \n           res_stack [j, 1] = accuracy_score(np.rint(m_t_x_train).T[j], y_train)\n           res_stack [j, 2] = accuracy_score(np.rint(model.transform(X_test)).T[j], y_test)\n        else: \n           res_stack [j, 1] = accuracy_score(m_t_x_train.reshape((X_train.shape[0],\\\n                                                                  nb_estimators,\\\n                                                                  y_train.unique().shape[0])).argmax(axis=2).T[j],\\\n                                             y_train)\n           res_stack [j, 2] = accuracy_score(model.transform(X_test).reshape((X_test.shape[0],\\\n                                                                              nb_estimators,\\\n                                                                              y_test.unique().shape[0])).argmax(axis=2).T[j],\\\n                                             y_test)\n    res_stack [len(model.estimators_) , 0] = 'Stack'\n    res_stack [len(model.estimators_) , 1] = accuracy_score(model.predict(X_train), y_train)\n    res_stack [len(model.estimators_) , 2] = accuracy_score(model.predict(X_test), y_test)  \n    models = res_stack.T[0]\n    score_train = res_stack.T[1]\n    score_test = res_stack.T[2]\n    plt.figure(figsize=(8,5))\n    plt.scatter(models, score_train, label='Train')\n    plt.scatter(models, score_test, label='Test')\n    plt.title('Model scores: accuracy')\n    plt.xticks(rotation='vertical')\n    plt.legend()\n    plt.show()\n    return res_stack\n\ndef score_stacking_r(model, X_train, y_train, X_test, y_test):\n    \"\"\"\n    Compute the score of the stacked regression estimator and of each level_0 estimator\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X_train: train feature dataframe \n    X_test: test feature dataframe\n    y_train: train target dataframe\n    y_test: test target dataframe\n    \n    Returns\n    -------\n    plotting: accuracy of estimators on train and test sets\n    res_stack: accuracy of estimators on train and test sets in a tabular\n    \"\"\"        \n    nb_estimators = len(model.estimators_)\n    res_stack = np.empty((nb_estimators + 1, 3), dtype='object')\n    m_t_x_train = model.transform(X_train)\n    for j in range(nb_estimators):\n        res_stack [j, 0] = [*model.named_estimators_.keys()][j]\n        res_stack [j, 1] = r2_score(np.rint(m_t_x_train).T[j], y_train)\n        res_stack [j, 2] = r2_score(np.rint(model.transform(X_test)).T[j], y_test)\n    res_stack [len(model.estimators_) , 0] = 'Stack'\n    res_stack [len(model.estimators_) , 1] = r2_score(model.predict(X_train), y_train)\n    res_stack [len(model.estimators_) , 2] = r2_score(model.predict(X_test), y_test)  \n    models = res_stack.T[0]\n    score_train = res_stack.T[1]\n    score_test = res_stack.T[2]\n    plt.figure(figsize=(8,5))\n    plt.scatter(models, score_train, label='Train')\n    plt.scatter(models, score_test, label='Test')\n    plt.title('Model scores: r2')\n    plt.xticks(rotation='vertical')\n    plt.legend()\n    plt.show()\n    return res_stack\n\ndef score_stacking(model, X_train, y_train, X_test, y_test):\n    \"\"\"\n    Compute the score of the stacked estimator and of each level_0 estimator\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X_train: train feature dataframe \n    X_test: test feature dataframe\n    y_train: train target dataframe\n    y_test: test target dataframe\n    \n    Returns\n    -------\n    plotting: accuracy of estimators on train and test sets\n    res_stack: accuracy of estimators on train and test sets in a tabular\n    plotting: model importance according to performance\n    mod_imp: model importance in a tabular\n    \"\"\"     \n    if is_classifier(model):\n       res_stack = score_stacking_c(model, X_train, y_train, X_test, y_test)\n    else:\n       res_stack = score_stacking_r(model, X_train, y_train, X_test, y_test) \n    nb_estimators = len(model.estimators_)\n    res_level_0 = res_stack[0:nb_estimators]\n    mod_imp = np.delete(res_level_0[res_level_0[:, 2].argsort()], 1, axis=1)\n    mod_imp.T[1] = mod_imp.T[1] / np.sum(mod_imp.T[1])\n    fig, ax = plt.subplots()\n    ax.barh(mod_imp.T[0], mod_imp.T[1])\n    ax.set_title(\"Model Importance according to performance\")\n    fig.tight_layout()\n    plt.show()\n    return res_stack, mod_imp\n\ndef find_coeff(model):\n    \"\"\"\n    Searches the wrapped model for the feature importances parameter.\n    \"\"\"\n    for attr in (\"feature_importances_\", \"coef_\"):\n        try:\n           return getattr(model, attr)\n        except AttributeError:\n           continue\n\n        raise YellowbrickTypeError(\n           \"could not find feature importances param on {}\".format(\n                model.__class__.__name__\n           )\n        )\n        \ndef model_importance_c(model, level_1_model):\n    \"\"\"\n    Compute the model importance depending on final estimator coefficients for classification\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n\n    Returns\n    -------\n    mod_imp: sorted array of model importance \n    \"\"\"        \n    level_0 = np.array(list(model.named_estimators_.keys()))\n    n_classes = model.classes_.shape[0]\n    n_models = len(model.estimators_)\n    model_coeff = find_coeff(model.final_estimator_)\n    \n    if level_1_model == 'tree':\n       if len(model_coeff) == n_models:\n          coeff = model_coeff.reshape(n_models)  \n       else:\n          coeff = sum(model_coeff.reshape(n_classes,n_models))\n            \n    if level_1_model == 'regression':\n       if len(model_coeff[0]) == n_models:\n          coeff = model_coeff.reshape(n_models)  \n       else:\n          coeff = sum(model_coeff.reshape(n_classes,n_models,n_classes)[i].T[i] for i in range(n_classes))\n            \n    model_importance = np.empty((len(level_0), 2), dtype='object')\n    for ind in range(len(level_0)):\n        model_importance[ind, 0] = level_0[ind]\n        model_importance[ind, 1] = np.abs(coeff[ind])\n    return model_importance[model_importance[:, 1].argsort()]\n\ndef model_importance_r(model, level_1_model):\n    \"\"\"\n    Compute the model importance depending on final estimator coefficients for regression\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    \n    Returns\n    -------\n    mod_imp: sorted array of model importance \n    \"\"\"         \n    level_0 = np.array(list(model.named_estimators_.keys()))\n    coeff = find_coeff(model.final_estimator_)\n    model_importance = np.empty((len(level_0), 2), dtype='object')\n    for ind in range(len(level_0)):\n        model_importance[ind, 0] = level_0[ind]\n        model_importance[ind, 1] = np.abs(coeff[ind])\n    return model_importance[model_importance[:, 1].argsort()]\n\ndef plot_model_importance(model, level_1_model):\n    \"\"\"\n    Compute the model importance depending on final estimator coefficients\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    \n    Returns\n    -------\n    plotting: model importance according to aggragator coefficients\n    mod_imp: sorted array of model importance \n    \"\"\"      \n    if is_classifier(model):\n       mod_imp = model_importance_c(model, level_1_model)\n    else:\n       mod_imp = model_importance_r(model, level_1_model)\n    mod_imp.T[1] = mod_imp.T[1] / np.sum(mod_imp.T[1])\n    fig, ax = plt.subplots()\n    ax.barh(mod_imp.T[0], mod_imp.T[1])\n    ax.set_title(\"Model Importance according to aggragator coefficients\")\n    fig.tight_layout()\n    plt.show()\n    return mod_imp\n\ndef plot_perm_importance(model, X, y, CPU):\n    \"\"\"\n    Compute the feature permutation importance\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X: feature dataframe\n    y: target dataframe\n    CPU: boolean for CPU training\n    \n    Returns\n    -------\n    plotting: feature permutation importance\n    perm_imp: sorted array of feature permutation importance\n    \"\"\"       \n    if is_classifier(model):\n       scoring = 'accuracy'\n    else:\n       scoring = 'r2'  \n    if CPU==True:\n       result = permutation_importance(model, X, y, scoring=scoring, n_repeats=10, n_jobs=-1)\n    else:\n       result = permutation_importance(model, X, y, scoring=scoring, n_repeats=10)\n    sorted_idx = result.importances_mean.argsort()\n    perm_imp = np.array([X.columns[sorted_idx], result.importances[sorted_idx].mean(axis=1).T]).T\n    perm_imp.T[1] = perm_imp.T[1] / np.sum(perm_imp.T[1])\n    fig, ax = plt.subplots()\n    ax.barh(perm_imp.T[0], perm_imp.T[1])\n    ax.set_title(\"Permutation Importance\")\n    fig.tight_layout()\n    plt.show()\n    return perm_imp\n\ndef plot_partial_dependence_c(model, X, features, CPU):\n    \"\"\"\n    Plot partial dependence of features for a given classification estimator and a given dataset\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X: feature dataframe\n    features: list of features\n    CPU: boolean for CPU training\n    \n    Returns\n    -------\n    plotting: partial dependence of input features\n    \"\"\"      \n    target = model.classes_\n    for ind in range(len(target)):\n        fig, ax = plt.subplots(figsize=(16, 8))\n        if CPU==True:\n           display = PartialDependenceDisplay.from_estimator(\n                     estimator = model,\n                     X = X,\n                     features = features,\n                     target = target[ind],\n                     n_cols = 2,\n                     kind = \"both\",\n                     subsample=50,\n                     n_jobs = -1,\n                     grid_resolution = 20,\n                     ice_lines_kw = {\"color\": \"tab:blue\", \"alpha\": 0.2, \"linewidth\": 0.5},\n                     pd_line_kw = {\"color\": \"tab:orange\", \"linestyle\": \"--\"},\n                     ax = ax,\n                     )\n        else:\n           display = PartialDependenceDisplay.from_estimator(\n                     estimator = model,\n                     X = X,\n                     features = features,\n                     target = target[ind],\n                     n_cols = 2,\n                     kind = \"both\",\n                     subsample=50,\n                     grid_resolution = 20,\n                     ice_lines_kw = {\"color\": \"tab:blue\", \"alpha\": 0.2, \"linewidth\": 0.5},\n                     pd_line_kw = {\"color\": \"tab:orange\", \"linestyle\": \"--\"},\n                     ax = ax,\n                     )\n        display.figure_.suptitle(\"Partial dependence for class \" + str(target[ind]))\n        display.figure_.subplots_adjust(hspace=0.3)\n        plt.show()\n    \ndef plot_partial_dependence_r(model, X, features, CPU):\n    \"\"\"\n    Plot partial dependence of features for a given regression estimator and a given dataset\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X: feature dataframe\n    features: list of features\n    CPU: boolean for CPU training\n    \n    Returns\n    -------\n    plotting: partial dependence of input features\n    \"\"\"      \n    fig, ax = plt.subplots(figsize=(16, 8))\n    if CPU==True:\n       display = PartialDependenceDisplay.from_estimator(\n                 estimator = model,\n                 X = X,\n                 features = features,\n                 n_cols = 2,\n                 kind=\"both\",\n                 subsample=50,\n                 n_jobs=-1,\n                 grid_resolution=20,\n                 ice_lines_kw={\"color\": \"tab:blue\", \"alpha\": 0.2, \"linewidth\": 0.5},\n                 pd_line_kw={\"color\": \"tab:orange\", \"linestyle\": \"--\"},\n                 ax = ax,\n                 )\n    else:\n       display = PartialDependenceDisplay.from_estimator(\n                 estimator = model,\n                 X = X,\n                 features = features,\n                 n_cols = 2,\n                 kind=\"both\",\n                 subsample=50,\n                 grid_resolution=20,\n                 ice_lines_kw={\"color\": \"tab:blue\", \"alpha\": 0.2, \"linewidth\": 0.5},\n                 pd_line_kw={\"color\": \"tab:orange\", \"linestyle\": \"--\"},\n                 ax = ax,\n                 )\n    display.figure_.suptitle(\"Partial dependence\")\n    display.figure_.subplots_adjust(hspace=0.3)\n    plt.show() \n\ndef plot_partial_dependence(model, X, features, CPU):\n    \"\"\"\n    Plot partial dependence of features for a given estimator and a given dataset\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X: feature dataframe\n    features: list of features, if features = [], partial dependences will be plot for all numeric features\n    CPU: boolean for CPU training\n    \n    Returns\n    -------\n    plotting: partial dependence of input features\n    \"\"\"    \n    # if input list of features is empty, we use the list of numeric features\n    if features == []:\n       features = X.select_dtypes([np.number]).columns.tolist() \n    else:\n    #  we keep only numeric features    \n       features = np.intersect1d(features, X.select_dtypes([np.number]).columns.tolist()).tolist() \n        \n    if features == []:\n       return \"No numeric feature\"\n    else:\n       if is_classifier(model):\n          plot_partial_dependence_c(model, X, features, CPU)\n       else:\n          plot_partial_dependence_r(model, X, features, CPU)\n\ndef plot_history(history):\n    \"\"\"\n    Plot learning curves of Keras neural network\n\n    Parameters\n    ----------\n    history: history of Keras neural network\n    \n    Returns\n    -------\n    plotting: learning curves of Keras neural network\n    \"\"\"     \n    pd.DataFrame(history.history).plot(figsize=(12, 9))\n    plt.title(\"Learning Curve\")\n    plt.xlabel(\"Epoch\")\n    plt.ylabel(\"Score\")\n    plt.legend()\n    plt.show()\n    \ndef K_confusion_matrix(model, X_train, y_train, X_test, y_test):\n    \"\"\"\n    Plot confusion matrix of a classification estimator on train and test sets\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X_train: train feature dataframe \n    X_test: test feature dataframe\n    y_train: train target dataframe\n    y_test: test target dataframe\n    \n    Returns\n    -------\n    plotting: confusion matrix on train and test sets\n    \"\"\"     \n    from sklearn.metrics import confusion_matrix\n    y_pred = model.predict(X_train)\n    if len(y_pred.shape)>1:\n       y_pred = np.around(y_pred).astype(int)\n       y_pred = np.argmax(y_pred, axis=1)\n       y_train = y_train.idxmax(axis=1)\n    cm = confusion_matrix(y_train, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot()\n    plt.title('Confusion matrix on train set')\n    plt.show()\n    y_pred = model.predict(X_test)\n    if len(y_pred.shape)>1:\n       y_pred = np.around(y_pred).astype(int)\n       y_pred = np.argmax(y_pred, axis=1)\n       y_test = y_test.idxmax(axis=1)\n    cm = confusion_matrix(y_test, y_pred)\n    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n    disp.plot()\n    plt.title('Confusion matrix on test set')\n    plt.show()\n    \ndef K_classification_report(model, X_train, y_train, X_test, y_test):\n    \"\"\"\n    Plot classification report of a classification estimator on train and test sets\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X_train: train feature dataframe \n    X_test: test feature dataframe\n    y_train: train target dataframe\n    y_test: test target dataframe\n    \n    Returns\n    -------\n    plotting: classification report on train and test sets\n    \"\"\"        \n    y_pred = model.predict(X_train)\n    if len(y_pred.shape)>1:\n       y_pred = np.around(y_pred).astype(int)\n       y_pred = np.argmax(y_pred, axis=1)\n       y_train = y_train.idxmax(axis=1)\n    cr=classification_report(y_train, y_pred, output_dict=True)\n    display(pd.DataFrame(cr).transpose().style.set_caption(\"Classification report on train set\"))\n    y_pred = model.predict(X_test)\n    if len(y_pred.shape)>1:\n       y_pred = np.around(y_pred).astype(int)\n       y_pred = np.argmax(y_pred, axis=1)\n       y_test = y_test.idxmax(axis=1)\n    cr=classification_report(y_test, y_pred, output_dict=True)\n    display(pd.DataFrame(cr).transpose().style.set_caption(\"Classification report on test set\"))\n    \ndef K_r2(model, X_train, y_train, X_test, y_test):\n    \"\"\"\n    Compute R^2 of a regression estimator on train and test sets.\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    X_train: train feature dataframe \n    X_test: test feature dataframe\n    y_train: train target dataframe\n    y_test: test target dataframe\n    \n    Returns\n    -------\n    array: scores on train and test sets\n    \"\"\"         \n    y_pred_train = model.predict(X_train)    \n    y_pred_test = model.predict(X_test)\n    dr2={'train': [r2_score(y_train, y_pred_train)],\\\n         'test': [r2_score(y_test, y_pred_test)]}\n    display(pd.DataFrame(data=dr2).style.hide_index())\n     \ndef fastapi_server(model, model_name, X, y):\n    \"\"\"\n    Generate the fastAPI server file, and save it in the current folder.\n\n    Parameters\n    ----------\n    model: estimator obtained after fitting\n    model_name : name of the saved model\n    X: feature dataframe \n    y: target dataframe\n    \n    \"\"\"   \n    string = \"\"\n    string = string  + \"from fastapi import FastAPI\\n\"\n    string = string  + \"from loguru import logger\\n\"\n    string = string  + \"from joblib import load\\n\"\n    string = string  + \"import pandas as pd\\n\"\n    string = string  + \"import numpy as np\\n\"\n    string = string  + \"import uvicorn\\n\"\n    string = string  + \"import ast\\n\"\n    string = string  + \"import time\\n\"\n    string = string  + \"from sklearn.base import is_classifier\\n\"\n    string = string  + \"from pydantic import BaseModel\\n\"\n    string = string  + \"\\n\"\n    string = string  + \"# Creating FastAPI instance\\n\"\n    string = string  + \"app = FastAPI()\\n\"\n    string = string  + \"\\n\"\n    string = string  + \"# Creating class to define the request body\\n\"\n    string = string  + \"# and the type hints of each attribute\\n\"\n\n    string = string  + \"\\n\"\n    string = string  + \"class request_body(BaseModel):\\n\"\n    for ind in range(X.dtypes.shape[0]):\n        if str(X.dtypes[ind])[0:5]=='float':\n           string = string + '      ' + X.columns[ind] + ': float\\n'\n        if str(X.dtypes[ind])[0:3]=='int':\n           string = string + '      ' + X.columns[ind] + ': int\\n'\n        if str(X.dtypes[ind])[0:4]=='uint':\n           string = string + '      ' + X.columns[ind] + ': int\\n'\n        if str(X.dtypes[ind])[0:6]=='object':\n           string = string + '      ' + X.columns[ind] + ': str\\n'\n        if str(X.dtypes[ind])[0:4]=='bool':\n           string = string + '      ' + X.columns[ind] + ': bool\\n'\n\n    string = string  + \"\\n\"\n    string = string  + \"# read dataframe schema\\n\"\n    string = string  + \"schema = pd.read_csv('schema.csv')\" \n    string = string  + \"\\n\"        \n    modulename = 'keras'\n    keras_bool = False\n    if modulename in sys.modules:\n       keras_bool = True \n       from EZS_deps.EZS_tech_func import keras_nn\n       if is_classifier(model):\n          string = string  + keras_nn('classification')\n       else:\n          string = string  + keras_nn('regression')\n        \n    string = string  + \"\\n\"        \n    string = string  + \"model = load('\" + model_name + \"')\\n\"\n\n    string = string  + \"\\n\"\n    if is_classifier(model):\n       string = string  + \"classes = \" + str(y.unique().tolist()) + \"\\n\"\n    \n    string = string  + \"\\n\"\n    string = string  + \"@app.get('/ping')\\n\"\n    string = string  + \"def pong():\\n\"\n    string = string  + \"    return {'ping': 'pong!'}\\n\"\n    \n    string = string  + \"\\n\"\n    string = string  + \"@app.post('/predict')\\n\"\n    string = string  + \"def predict(data : request_body):\\n\"\n    string = string  + \"\\n\"\n    string = string  + \"    elaps_start_time = time.time()\\n\"\n    string = string  + \"    cpu_start_time = time.process_time()\\n\"\n    string = string  + \"\\n\"\n    string = string  + \"    # Making the data in a form suitable for prediction\\n\"\n    string = string  + \"    test_data = [[\\n\"\n    for ind in range(X.columns.shape[0]):\n        string = string  + \"              data.\" + X.columns[ind] + ',\\n'\n    string = string  + \"    ]]\\n\"\n    \n    string = string  + \"\\n\"\n    \n    string = string  + \"    # Check input data\\n\"\n    string = string  + \"    data_err = []\\n\"\n    string = string  + \"    for ind in range(len(test_data[0])):\\n\"\n    string = string  + \"        if schema.iloc[ind][1] == 'num':\\n\"\n    string = string  + \"           interval = ast.literal_eval(schema.iloc[ind][2])\\n\"\n    string = string  + \"           if (test_data[0][ind] < interval[0]) | (test_data[0][ind] > interval[1]):\\n\"\n    string = string  + \"              data_err.append(schema.iloc[ind][0])\\n\"\n    string = string  + \"        if schema.iloc[ind][1] == 'cat':\\n\"\n    string = string  + \"           domain = ast.literal_eval(schema.iloc[ind][2])\\n\"\n    string = string  + \"           if not(np.isin(test_data[0][ind], domain)):\\n\"\n    string = string  + \"              data_err.append(schema.iloc[ind][0])\\n\"\n    string = string  + \"\\n\"\n\n                \n    if is_classifier(model):\n       string = string  + \"    # Predicting the Class\\n\"\n       string = string  + \"    result = model.predict(pd.DataFrame(test_data,\\n\"\n       string = string  + \"                                        columns=[\\n\"\n       for ind in range(X.columns.shape[0]):\n           string = string  + \"                                                  '\" + X.columns[ind] + \"',\\n\"\n       string = string  + \"                          ]))[0].item()\\n\"\n       string = string  + \"\\n\"\n\n       string = string  + \"    elaps_end_time = time.time()\\n\"\n       string = string  + \"    cpu_end_time = time.process_time()\\n\"\n       string = string  + \"    elapsed_time = np.round((elaps_end_time - elaps_start_time) * 1000)\\n\"\n       string = string  + \"    elaps = str(elapsed_time) + 'ms'\\n\"\n       string = string  + \"    cpu_time = np.round((cpu_end_time - cpu_start_time) * 1000)\\n\"\n       string = string  + \"    cpu = str(cpu_time) + 'ms'\\n\"       \n       string = string  + \"\\n\"\n       string = string  + \"    # Return the Result\\n\"\n       string = string  + \"    return { 'class' : classes[result], 'error' : data_err, 'elapsed time' : elaps, 'cpu time' : cpu}\\n\"\n    else: \n       string = string  + \"    # Predicting the regression value\\n\"\n       if keras_bool: \n          string = string  + \"    result = model.predict(pd.DataFrame(np.array([test_data[0],]*2),\\n\"\n       else:\n          string = string  + \"    result = model.predict(pd.DataFrame(test_data,\\n\"        \n       string = string  + \"                                        columns=[\\n\"\n       for ind in range(X.columns.shape[0]):\n           string = string  + \"                                                 '\" + X.columns[ind] + \"',\\n\"\n       string = string  + \"                          ]))[0].item()\\n\"\n       string = string  + \"\\n\"\n       string = string  + \"    elaps_end_time = time.time()\\n\"\n       string = string  + \"    cpu_end_time = time.process_time()\\n\"\n       string = string  + \"    elapsed_time = np.round((elaps_end_time - elaps_start_time) * 1000)\\n\"\n       string = string  + \"    elaps = str(elapsed_time) + 'ms'\\n\"\n       string = string  + \"    cpu_time = np.round((cpu_end_time - cpu_start_time) * 1000)\\n\"\n       string = string  + \"    cpu = str(cpu_time) + 'ms'\\n\"\n       string = string  + \"\\n\"\n       string = string  + \"    # Return the Result\\n\"\n       string = string  + \"    return { 'regression_value' : result, 'error' : data_err, 'elapsed time' : elaps, 'cpu time' : cpu}\\n\"\n    \n    string = string  + \"\\n\"\n    string = string  + \"from pyngrok import ngrok\\n\"\n    string = string  + \"ngrok_tunnel = ngrok.connect(8000)\\n\"\n    string = string  + \"ngrok_tunnel\\n\"\n\n    string = string  + \"\\n\"\n    string = string  + \"import nest_asyncio\\n\"\n    string = string  + \"\\n\"\n    string = string  + \"nest_asyncio.apply()\\n\"\n    string = string  + \"uvicorn.run(app, port=8000)\\n\"\n\n    file_server = open(\"server.py\", \"w\") \n    file_server.write(string)\n    file_server.close()  \n\ndef store_data(name, level_1_model, score_stack_0, score_stack_1, score_stack_2, \n           model_imp_0, model_imp_1, model_imp_2, \n           feature_importance_0, feature_importance_1, feature_importance_2):\n    import sqlite3\n    conn = sqlite3.connect('/home/philippe/development/python/EZStacking/EZS_deps/EZS_store.db')\n    cursor = conn.cursor()\n\n    search_problem = cursor.execute(\"SELECT name FROM problem WHERE name = ?\", (name,))\n    problem_name = search_problem.fetchone()\n    if problem_name == None:\n       cursor.execute(\"INSERT INTO problem (name, path , type, target) VALUES(?, ?, ?, ?)\", (name, path, problem_type, target_col))\n\n    search_version = cursor.execute(\"SELECT MAX(version) FROM solution WHERE name = ?\", (name,))\n    row = search_version.fetchone()\n    if row == (None,):\n       version = 1\n    else:\n       version = row[0] + 1\n\n    cursor.execute(\"INSERT INTO solution (name, version, correlation, nb_model, nb_feature, score, test_size) VALUES(?, ?, ?, ?, ?, ?, ?)\", \\\n                    (name, version, threshold_corr, threshold_model, threshold_feature, threshold_score, test_size));\n\n    schema = pd.read_csv('schema.csv')\n    for ind in range(len(user_drop_cols)):\n        cursor.execute(\"INSERT INTO eda (name, version, feature, type, range, drop_user, drop_correlation, target)  VALUES(?, ?, ?, ?, ?, ?, ?, ?)\", \\\n                        (name, version, user_drop_cols[ind], None, None, 1, 0, 0));\n    for ind in range(schema.shape[0]):\n        if schema['column_name'][ind] in correlated_features:\n           drop_correlation = True\n        else:\n           drop_correlation = False\n\n        cursor.execute(\"INSERT INTO eda (name, version, feature, type, range, drop_user, drop_correlation, target)  VALUES(?, ?, ?, ?, ?, ?, ?, ?)\", \\\n                        (name, version, schema['column_name'][ind], schema['column_type'][ind], schema['column_range'][ind], 0, drop_correlation, 0));\n\n    cursor.execute(\"INSERT INTO eda (name, version, feature, type, range, drop_user, drop_correlation, target)  VALUES(?, ?, ?, ?, ?, ?, ?, ?)\", \\\n                        (name, version, target_col, None, None, 0, 0, 1));\n\n    for ind in range(3):\n        cursor.execute(\"INSERT INTO model (name, version, step, L1_model) VALUES (?, ?, ?, ?)\", \\\n                        (name, version, ind+1, level_1_model));\n\n        score_stack = locals()[\"_\".join(['score_stack', str(ind)])]\n        for ind2 in range(score_stack.shape[0]):\n            cursor.execute(\"INSERT INTO model_score (name, version, step, model, train_score, test_score) VALUES(?, ?, ?, ?, ?, ?)\", \\\n                            (name, version, ind+1, score_stack[ind2,0], score_stack[ind2,1], score_stack[ind2,2]));\n\n        model_imp = locals()[\"_\".join(['model_imp', str(ind)])]\n        for ind2 in range(model_imp.shape[0]):\n            cursor.execute(\"INSERT INTO model_importance (name, version, step, model, importance) VALUES(?, ?, ?, ?, ?)\", \\\n                            (name, version, ind+1, model_imp[ind2,0], model_imp[ind2,1]));\n\n        feature_importance = locals()[\"_\".join(['feature_importance', str(ind)])]\n        for ind2 in range(feature_importance.shape[0]):\n            cursor.execute(\"INSERT INTO feature_importance (name, version, step, feature, importance) VALUES(?, ?, ?, ?, ?)\", \\\n                            (name, version, ind+1, feature_importance[ind2,0], feature_importance[ind2,1]));\n\n    # cursor.execute(\"DELETE FROM problem WHERE name = ?\", (name,))\n\n    conn.commit()\n    conn.close()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Project name","metadata":{}},{"cell_type":"code","source":"name = 'Solar Power Generation'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Exploratory Data Analysis ","metadata":{}},{"cell_type":"markdown","source":"## File and parameters loading","metadata":{}},{"cell_type":"code","source":"problem_type = 'regression'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data_size = 'small'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path = '/kaggle/input/solar-power-generation/BigML_Dataset_5f50a4cc0d052e40e6000034.csv'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv(path)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"target_col = 'Power Generated'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Thresholds & other parameters","metadata":{}},{"cell_type":"code","source":"threshold_NaN = 0.5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_cat = 5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_Z = 3.0","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_size = 0.33","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_entropy = 0.75","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undersampling = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"undersampler = 'Random'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_corr = 0.75","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_model = 6","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_score = 0.8","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_feature = 4","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"CPU = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"level_1_model = 'regression'","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Drop user's columns:","metadata":{}},{"cell_type":"code","source":"user_drop_cols = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset before deletion","metadata":{}},{"cell_type":"code","source":"display(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop(user_drop_cols, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Dataset after deletion","metadata":{}},{"cell_type":"code","source":"display(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataset copy","metadata":{}},{"cell_type":"code","source":"df_copy = df.copy()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Information","metadata":{}},{"cell_type":"code","source":"df.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Some records","metadata":{}},{"cell_type":"code","source":"display(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataframe structure","metadata":{}},{"cell_type":"code","source":"plot_dataframe_structure(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Dataframe statistics","metadata":{}},{"cell_type":"code","source":"display(df.describe().T)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Which columns could be categorical ?","metadata":{}},{"cell_type":"code","source":"plot_categorical(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset Cleaning","metadata":{}},{"cell_type":"markdown","source":"### Duplicate rows:","metadata":{}},{"cell_type":"code","source":"duplicates(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Drop NaN:","metadata":{}},{"cell_type":"code","source":"df, drop_cols = drop_na(df, threshold_NaN)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Set of dropped columns: NaN","metadata":{}},{"cell_type":"code","source":"dropped_cols = np.unique(np.concatenate((drop_cols, user_drop_cols)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display(dropped_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Encoding data:","metadata":{}},{"cell_type":"code","source":"df, encoded_cols = encoding(df, threshold_cat, target_col)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Imputing NaN using IterativeImputer","metadata":{}},{"cell_type":"code","source":"visualizer = MissingValuesBar(features=df.select_dtypes(include=np.number).columns.tolist())\nvisualizer.fit(df.select_dtypes(include=np.number))\nvisualizer.show();","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Imputation","metadata":{}},{"cell_type":"code","source":"df = imputation(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Data compression:","metadata":{}},{"cell_type":"code","source":"df = downcast_dtypes(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Dataframe structure after compression","metadata":{}},{"cell_type":"code","source":"plot_dataframe_structure(df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Outliers:","metadata":{}},{"cell_type":"code","source":"df = outliers(df, threshold_Z)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Plottings","metadata":{}},{"cell_type":"markdown","source":"# Ranking ","metadata":{}},{"cell_type":"markdown","source":"#### Ranking 1D ","metadata":{}},{"cell_type":"code","source":"rank1d(df);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Ranking 2D ","metadata":{}},{"cell_type":"markdown","source":"##### Ranking 2D according to Pearson","metadata":{}},{"cell_type":"code","source":"rank2d(df, algorithm='pearson');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Ranking 2D based on covariance","metadata":{}},{"cell_type":"code","source":"rank2d(df, algorithm='covariance');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Ranking 2D according to Spearman","metadata":{}},{"cell_type":"code","source":"rank2d(df, algorithm='spearman');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Ranking 2D according to Kendalltau","metadata":{}},{"cell_type":"code","source":"rank2d(df, algorithm='kendalltau');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Correlation","metadata":{}},{"cell_type":"code","source":"corr = df.corr() \ncorr.style.background_gradient(cmap='coolwarm')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"correlated_features = correlated_columns(df, threshold_corr, target_col) \ndropped_cols = np.unique(np.concatenate((drop_cols, correlated_features)))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Splitting dataframe in features and targets","metadata":{}},{"cell_type":"code","source":"y = df[target_col]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(target_col, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"##### Correlation with Yellow Bricks","metadata":{}},{"cell_type":"code","source":"feature_correlation(X, y);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"feature_correlation(X, y, method='mutual_info-regression');","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature importance (a priori)","metadata":{}},{"cell_type":"markdown","source":"#### According to decision tree","metadata":{}},{"cell_type":"code","source":"feature_importances(DecisionTreeRegressor(), X, y);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### According to elasticnet regression","metadata":{}},{"cell_type":"code","source":"feature_importances(ElasticNet(alpha=0.01, l1_ratio=0.5), X, y);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check columns that should be dropped","metadata":{}},{"cell_type":"code","source":"print(dropped_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Splittings ","metadata":{}},{"cell_type":"code","source":"df = df_copy","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting dataframe in features and targets","metadata":{}},{"cell_type":"code","source":"y = df[target_col]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(target_col, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dimensions","metadata":{}},{"cell_type":"code","source":"nb_features = len(X.columns.tolist())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_targets = 1","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_size = nb_features + nb_targets + 2","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting data in train and test sets ","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = split(X, y, test_size=test_size, threshold_entropy=threshold_entropy, undersampling= undersampling, undersampler= undersampler, random_state = random_state)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Modelling","metadata":{}},{"cell_type":"markdown","source":"## Model building","metadata":{}},{"cell_type":"markdown","source":"### Pipeline building","metadata":{}},{"cell_type":"markdown","source":"#### Select the categorical and numerical columns","metadata":{}},{"cell_type":"code","source":"cat_selector = make_column_selector(dtype_include=object)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_selector = make_column_selector(dtype_include=np.number)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### For models based on tree","metadata":{}},{"cell_type":"code","source":"cat_tree_processor = make_pipeline(SimpleImputer(strategy='most_frequent'), OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_tree_processor = make_pipeline(IterativeImputer(random_state=0, add_indicator=True))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tree_preprocessor = make_pipeline(make_column_transformer((num_tree_processor, num_selector), (cat_tree_processor, cat_selector)), Decorrelator(threshold_corr))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### For models not based on tree","metadata":{}},{"cell_type":"code","source":"cat_ntree_processor = make_pipeline(SimpleImputer(strategy='most_frequent'), OneHotEncoder(handle_unknown='ignore', sparse=False))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"num_ntree_processor = make_pipeline(IterativeImputer(random_state=0, add_indicator=True), StandardScaler())","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ntree_preprocessor = make_pipeline(make_column_transformer((num_ntree_processor, num_selector), (cat_ntree_processor, cat_selector)), Decorrelator(threshold_corr))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Level-0 models","metadata":{}},{"cell_type":"code","source":"level_0 = [ \n          ('GPRL', make_pipeline(ntree_preprocessor, GaussianProcessRegressor(kernel = ConstantKernel() * DotProduct() + ConstantKernel() + WhiteKernel(), random_state = random_state))), \n          ('GPRR', make_pipeline(ntree_preprocessor, GaussianProcessRegressor(kernel = ConstantKernel() * RBF() + ConstantKernel() + WhiteKernel(), random_state = random_state))), \n          ('GPRQ', make_pipeline(ntree_preprocessor, GaussianProcessRegressor(kernel = ConstantKernel() * RationalQuadratic() + ConstantKernel() + WhiteKernel(), random_state = random_state))), \n          ('DTRF', make_pipeline(tree_preprocessor, DecisionTreeRegressor(criterion='friedman_mse', random_state = random_state))), \n          ('DTRA', make_pipeline(tree_preprocessor, DecisionTreeRegressor(criterion='absolute_error', random_state = random_state))), \n          ('DTRP', make_pipeline(tree_preprocessor, DecisionTreeRegressor(criterion='poisson', random_state = random_state))), \n          ('RFRS', make_pipeline(tree_preprocessor, RandomForestRegressor(criterion='squared_error', n_estimators=100, random_state = random_state))), \n          ('RFRA', make_pipeline(tree_preprocessor, RandomForestRegressor(criterion='absolute_error', n_estimators=100, random_state = random_state))), \n          ('RFRP', make_pipeline(tree_preprocessor, RandomForestRegressor(criterion='poisson', n_estimators=100, random_state = random_state))), \n          ('ABR', make_pipeline(tree_preprocessor, AdaBoostRegressor(random_state = random_state))), \n          ('HGBR', make_pipeline(tree_preprocessor, HistGradientBoostingRegressor(early_stopping=True, random_state = random_state))), \n          ('ELNE', make_pipeline(ntree_preprocessor, ElasticNet(alpha=0.01, l1_ratio=0.15, random_state = random_state))), \n          ('ELNECV', make_pipeline(ntree_preprocessor, ElasticNetCV(cv=5, random_state = random_state))), \n          ('LINR', make_pipeline(ntree_preprocessor, LinearRegression())), \n          ('MLPR1', make_pipeline(ntree_preprocessor, MLPRegressor(hidden_layer_sizes = (layer_size, ), max_iter=2000, early_stopping=True, random_state = random_state))), \n          ('MLPR2', make_pipeline(ntree_preprocessor, MLPRegressor(hidden_layer_sizes = (layer_size, layer_size,), max_iter=2000, early_stopping=True, random_state = random_state))), \n          ('KNRU', make_pipeline(ntree_preprocessor, KNeighborsRegressor(weights='uniform'))), \n          ('KNRD', make_pipeline(ntree_preprocessor, KNeighborsRegressor(weights='distance'))), \n          ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Level-1 model","metadata":{}},{"cell_type":"code","source":"level_1 = LinearRegression()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Stacking for regression","metadata":{}},{"cell_type":"code","source":"model = StackingRegressor(level_0, final_estimator=level_1, n_jobs=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model fitting","metadata":{}},{"cell_type":"code","source":"%%time \nset_config(display='diagram') \nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model evaluation","metadata":{}},{"cell_type":"markdown","source":"### Model scoring","metadata":{}},{"cell_type":"code","source":"score_stack_0, mod_imp_score_0 = score_stacking(model, X_train, y_train, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Residuals plot","metadata":{}},{"cell_type":"code","source":"residuals_plot(model, X_train, y_train, X_test, y_test);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Prediction error","metadata":{}},{"cell_type":"code","source":"prediction_error(model, X_train, y_train, X_test, y_test);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model inspection","metadata":{}},{"cell_type":"markdown","source":"### Model importance","metadata":{}},{"cell_type":"code","source":"model_imp_0 = plot_model_importance(model, level_1_model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Feature permutation importance (a posteriori)","metadata":{}},{"cell_type":"code","source":"feature_importance_0 = plot_perm_importance(model, X_test, y_test, CPU)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Level-0 model elimination","metadata":{}},{"cell_type":"code","source":"threshold_model = 6","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"threshold_score = 0.8","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Filtered Level-0 models","metadata":{}},{"cell_type":"code","source":"level_0_f = model_filtering(level_0, model_imp_0, threshold_model, score_stack_0, threshold_score)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Level-1 model with filtration","metadata":{}},{"cell_type":"code","source":"level_1 = LinearRegression()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Build filtered model","metadata":{}},{"cell_type":"code","source":"model = StackingRegressor(level_0_f, final_estimator=level_1, n_jobs=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Filtered Model fitting","metadata":{}},{"cell_type":"code","source":"%%time \nset_config(display='diagram') \nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Filtered Model evaluation","metadata":{}},{"cell_type":"markdown","source":"### Filtered Model scoring","metadata":{}},{"cell_type":"code","source":"score_stack_1, mod_imp_score_1 = score_stacking(model, X_train, y_train, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filtered feature permutation importance","metadata":{}},{"cell_type":"code","source":"feature_importance_1 = plot_perm_importance(model, X_test, y_test, CPU)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Filtered feature elimination","metadata":{}},{"cell_type":"code","source":"best_feature, worst_feature = feature_filtering(feature_importance_1, threshold_feature)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dropped_cols = np.unique(np.concatenate((dropped_cols, worst_feature))).tolist()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Check those columns, they should be dropped","metadata":{}},{"cell_type":"code","source":"print(dropped_cols)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filtered Residuals plot","metadata":{}},{"cell_type":"code","source":"residuals_plot(model, X_train, y_train, X_test, y_test);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filtered Prediction error","metadata":{}},{"cell_type":"code","source":"prediction_error(model, X_train, y_train, X_test, y_test);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Filtered Model inspection","metadata":{}},{"cell_type":"markdown","source":"### Filtered Model importance","metadata":{}},{"cell_type":"code","source":"model_imp_1 = plot_model_importance(model, level_1_model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Filtered Feature permutation importance (a posteriori)","metadata":{}},{"cell_type":"code","source":"plot_perm_importance(model, X_test, y_test, CPU)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Model","metadata":{}},{"cell_type":"code","source":"df = df.drop(dropped_cols, axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting dataframe in features and targets for final model","metadata":{}},{"cell_type":"code","source":"y = df[target_col] ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = df.drop(target_col, axis=1) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Dimensions","metadata":{}},{"cell_type":"code","source":"nb_features = len(X.columns.tolist()) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"nb_targets = 1 ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"layer_size = nb_features + nb_targets + 2 ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Splitting data in train and test sets ","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = split(X, y, test_size=test_size, threshold_entropy=threshold_entropy, undersampling=undersampling, undersampler=undersampler, random_state=random_state) ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#### Build final model","metadata":{}},{"cell_type":"code","source":"model = StackingRegressor(level_0_f, final_estimator=level_1, n_jobs=-1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Model fitting","metadata":{}},{"cell_type":"code","source":"%%time \nset_config(display='diagram') \nmodel.fit(X_train, y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Model evaluation","metadata":{}},{"cell_type":"markdown","source":"### Final Model scoring","metadata":{}},{"cell_type":"code","source":"score_stack_2, mod_imp_score_2 = score_stacking(model, X_train, y_train, X_test, y_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final feature permutation importance","metadata":{}},{"cell_type":"code","source":"feature_importance_2 = feature_importance = plot_perm_importance(model, X_test, y_test, CPU)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Residuals plot","metadata":{}},{"cell_type":"code","source":"residuals_plot(model, X_train, y_train, X_test, y_test);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Prediction error","metadata":{}},{"cell_type":"code","source":"prediction_error(model, X_train, y_train, X_test, y_test);","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Final Model inspection","metadata":{}},{"cell_type":"markdown","source":"### Final Model importance","metadata":{}},{"cell_type":"code","source":"model_imp_2 = plot_model_importance(model, level_1_model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Feature permutation importance (a posteriori)","metadata":{}},{"cell_type":"code","source":"plot_perm_importance(model, X_test, y_test, CPU)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Final Partial Dependence & Individual Conditional Expectation ","metadata":{}},{"cell_type":"markdown","source":"#### Final Features of interest","metadata":{}},{"cell_type":"code","source":"features_of_interest = []","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_partial_dependence(model, X_test, features_of_interest, CPU)  ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#store_data(name, level_1_model, score_stack_0, score_stack_1, score_stack_2, \n#           model_imp_0, model_imp_1, model_imp_2, \n#           feature_importance_0, feature_importance_1, feature_importance_2)","metadata":{},"execution_count":null,"outputs":[]}]}